{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/deshwalmahesh/yolov7-deepsort-tracking/blob/master/Colab%20Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4G5WYnfI3fd"
   },
   "source": [
    "# Clone Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oM9-ZmN1IgW0",
    "outputId": "03cb564e-f439-4c2b-b657-dc6bd4dcf498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "d:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\yolov7-deepsort-tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7-deepsort-tracking'...\n",
      "Updating files:  41% (47/113)\n",
      "Updating files:  42% (48/113)\n",
      "Updating files:  43% (49/113)\n",
      "Updating files:  44% (50/113)\n",
      "Updating files:  45% (51/113)\n",
      "Updating files:  46% (52/113)\n",
      "Updating files:  47% (54/113)\n",
      "Updating files:  48% (55/113)\n",
      "Updating files:  49% (56/113)\n",
      "Updating files:  50% (57/113)\n",
      "Updating files:  51% (58/113)\n",
      "Updating files:  52% (59/113)\n",
      "Updating files:  53% (60/113)\n",
      "Updating files:  54% (62/113)\n",
      "Updating files:  55% (63/113)\n",
      "Updating files:  56% (64/113)\n",
      "Updating files:  57% (65/113)\n",
      "Updating files:  58% (66/113)\n",
      "Updating files:  59% (67/113)\n",
      "Updating files:  60% (68/113)\n",
      "Updating files:  61% (69/113)\n",
      "Updating files:  62% (71/113)\n",
      "Updating files:  63% (72/113)\n",
      "Updating files:  64% (73/113)\n",
      "Updating files:  65% (74/113)\n",
      "Updating files:  66% (75/113)\n",
      "Updating files:  67% (76/113)\n",
      "Updating files:  68% (77/113)\n",
      "Updating files:  69% (78/113)\n",
      "Updating files:  70% (80/113)\n",
      "Updating files:  71% (81/113)\n",
      "Updating files:  72% (82/113)\n",
      "Updating files:  73% (83/113)\n",
      "Updating files:  74% (84/113)\n",
      "Updating files:  75% (85/113)\n",
      "Updating files:  76% (86/113)\n",
      "Updating files:  77% (88/113)\n",
      "Updating files:  78% (89/113)\n",
      "Updating files:  79% (90/113)\n",
      "Updating files:  80% (91/113)\n",
      "Updating files:  81% (92/113)\n",
      "Updating files:  82% (93/113)\n",
      "Updating files:  83% (94/113)\n",
      "Updating files:  84% (95/113)\n",
      "Updating files:  85% (97/113)\n",
      "Updating files:  86% (98/113)\n",
      "Updating files:  87% (99/113)\n",
      "Updating files:  88% (100/113)\n",
      "Updating files:  89% (101/113)\n",
      "Updating files:  90% (102/113)\n",
      "Updating files:  91% (103/113)\n",
      "Updating files:  92% (104/113)\n",
      "Updating files:  93% (106/113)\n",
      "Updating files:  94% (107/113)\n",
      "Updating files:  95% (108/113)\n",
      "Updating files:  96% (109/113)\n",
      "Updating files:  97% (110/113)\n",
      "Updating files:  98% (111/113)\n",
      "Updating files:  99% (112/113)\n",
      "Updating files: 100% (113/113)\n",
      "Updating files: 100% (113/113), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/deshwalmahesh/yolov7-deepsort-tracking\n",
    "%cd yolov7-deepsort-tracking\n",
    "\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjbaRMUEI0Q_"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nvvl4-tHIs7n"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetection_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracking_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mbridge_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\tracking_helpers.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#tf.compat.v1.disable_eager_execution()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "from detection_helpers import *\n",
    "from tracking_helpers import *\n",
    "from  bridge_wrapper import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTAWru5zJED6"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "UVY6sVZ_I9CW",
    "outputId": "354eaf28-fdab-45ad-8f36-3ea990088f0b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m detector \u001b[38;5;241m=\u001b[39m Detector(classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m32\u001b[39m]) \u001b[38;5;66;03m# it'll detect ONLY [person,horses,sports ball]. class = None means detect all classes. List info at: \"data/coco.yaml\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./yolov7-custom-dataset.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# pass the path to the trained weight file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pass in any image path or Numpy Image using 'BGR' format\u001b[39;00m\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./IO_data/input/images/plants.JPEG\u001b[39m\u001b[38;5;124m'\u001b[39m, plot_bb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# plot_bb = False output the predictions as [x,y,w,h, confidence, class]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\detection_helpers.py:40\u001b[0m, in \u001b[0;36mDetector.load_model\u001b[1;34m(self, weights, img_size, trace, classify)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mweights: Path to the model\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mimg_size: Input image size of the model\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mtrace: Whether to trace the model or not\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mclassify: whether to load the second stage classifier model or not\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# half precision only supported on CUDA\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load FP32 model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m.\u001b[39mmax())  \u001b[38;5;66;03m# model stride\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgsz \u001b[38;5;241m=\u001b[39m check_img_size(img_size, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride)  \u001b[38;5;66;03m# check img_size\u001b[39;00m\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\models\\experimental.py:88\u001b[0m, in \u001b[0;36mattempt_load\u001b[1;34m(weights, map_location)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(weights, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [weights]:\n\u001b[0;32m     87\u001b[0m     attempt_download(w)\n\u001b[1;32m---> 88\u001b[0m     ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     model\u001b[38;5;241m.\u001b[39mappend(ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mfuse()\u001b[38;5;241m.\u001b[39meval())  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Compatibility updates\u001b[39;00m\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\.venv\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\.venv\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32md:\\Proyectos\\HAU\\codigo\\tracking\\yolov7-deepsort-tracking\\.venv\\lib\\site-packages\\torch\\serialization.py:1515\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "detector = Detector(classes = [0,17,32]) # it'll detect ONLY [person,horses,sports ball]. class = None means detect all classes. List info at: \"data/coco.yaml\"\n",
    "detector.load_model('./yolov7-custom-dataset.pt',) # pass the path to the trained weight file\n",
    "\n",
    "\n",
    "# Pass in any image path or Numpy Image using 'BGR' format\n",
    "result = detector.detect('./IO_data/input/images/plants.JPEG', plot_bb = True) # plot_bb = False output the predictions as [x,y,w,h, confidence, class]\n",
    "\n",
    "\n",
    "if len(result.shape) == 3:# If it is image, convert it to proper image. detector will give \"BGR\" image\n",
    "    result = Image.fromarray(cv2.cvtColor(result,cv2.COLOR_BGR2RGB)) \n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26fcd6P1JM2o"
   },
   "source": [
    "# Tracking\n",
    "**NOTE: Colab won't show you the video using `OpenCV` here. So keep `show_live = False` on `Colab`**\n",
    "\n",
    "You can save the `AVI` video first, convert it to `MP4` and then render it given the steps below. [Follow this link for conversion and display](https://stackoverflow.com/questions/60977179/how-to-play-avi-file-in-google-colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INLCQnXIJKFv",
    "outputId": "365fc9ff-654d-4c76-c625-113bcc506fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame no: 257 || Current FPS: 0.32 || Objects tracked: 14\n",
      "Processed frame no: 258 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 259 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 260 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 261 || Current FPS: 0.37 || Objects tracked: 14\n",
      "Processed frame no: 262 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 263 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 264 || Current FPS: 0.37 || Objects tracked: 14\n",
      "Processed frame no: 265 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 266 || Current FPS: 0.38 || Objects tracked: 14\n",
      "Processed frame no: 267 || Current FPS: 0.38 || Objects tracked: 13\n",
      "Processed frame no: 268 || Current FPS: 0.37 || Objects tracked: 13\n",
      "Processed frame no: 269 || Current FPS: 0.38 || Objects tracked: 13\n",
      "Processed frame no: 270 || Current FPS: 0.38 || Objects tracked: 13\n",
      "Processed frame no: 271 || Current FPS: 0.38 || Objects tracked: 14\n"
     ]
    }
   ],
   "source": [
    "# Initialise  class that binds detector and tracker in one class\n",
    "tracker = YOLOv7_DeepSORT(reID_model_path=\"./deep_sort/model_weights/mars-small128.pb\", detector=detector)\n",
    "\n",
    "# output = None will not save the output video\n",
    "tracker.track_video(\"./IO_data/input/video/IMG_1172-slow-walk.MP4\", output=\"./IO_data/output/IMG_1172-slow-walk.avi\", show_live = True, skip_frames = 0, count_objects = True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT5RgZITJ_pD"
   },
   "source": [
    "## Scripts for handling Videos on `Colab / Jupyter Notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsQWf_CdKAE9"
   },
   "source": [
    "### Download a video from Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SucR5EBeKOmM"
   },
   "outputs": [],
   "source": [
    "# ! pip install pytube\n",
    "from pytube import YouTube \n",
    "\n",
    "link = \"https://www.youtube.com/watch?v=kYIf8I1dvdo\"\n",
    "yt = YouTube(link)  \n",
    "\n",
    "try:\n",
    "    yt.streams.filter(progressive = True, file_extension = \"mp4\", resolution = \"720p\").first().download(output_path = \"./\", filename = \"test.mp4\",)\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SbYql1pKAvL"
   },
   "source": [
    "### Trim an existing video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgelEmJ_KSrb"
   },
   "outputs": [],
   "source": [
    "# ! pip install moviepy\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "ffmpeg_extract_subclip(\"test.mp4\", 10, 100, targetname=\"trim.mp4\") # trim from 10th second to 100th second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyrMS1WBKLF4"
   },
   "source": [
    "### Show an MP4 video Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPRPEoAzJq_R"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open('trim.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMl4i1c/Wcd8kVeOsx26BlQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Colab Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
